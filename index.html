<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Working through the book Introduction to Machine Learning by Andreas Muller &amp; Sarah Guido">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Machine Learning With Python</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="rss.xml">
<link rel="canonical" href="http://necromuralist.github.io/machine_learning_with_python/">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]--><link rel="prefetch" href="posts/knn-regression/" type="text/html">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://necromuralist.github.io/machine_learning_with_python/">

                <span id="blog-title">Machine Learning With Python</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>
                </li>
<li>
<a href="rss.xml">RSS feed</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/knn-regression/" class="u-url">KNN Regression</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                hades
            </span></p>
            <p class="dateline"><a href="posts/knn-regression/" rel="bookmark"><time class="published dt-published" datetime="2017-07-09T19:19:00-07:00" title="2017-07-09 19:19">2017-07-09 19:19</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<div class="section" id="introduction">
<h2>Introduction</h2>
<p>This will look at using K-Nearest Neighbors for regression. First I'll look at a synthetic data-set and then a dataset that was created to study the effect of polution on the housing prices in Boston.</p>
<div class="section" id="imports">
<h3>Imports</h3>
<pre class="code ipython"><a name="rest_code_1f83f6559f7345b6a714749ae3593d2f-1"></a><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">jit</span>
<a name="rest_code_1f83f6559f7345b6a714749ae3593d2f-2"></a><span class="kn">import</span> <span class="nn">numpy</span>
<a name="rest_code_1f83f6559f7345b6a714749ae3593d2f-3"></a><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pyplot</span>
<a name="rest_code_1f83f6559f7345b6a714749ae3593d2f-4"></a><span class="kn">import</span> <span class="nn">seaborn</span>
<a name="rest_code_1f83f6559f7345b6a714749ae3593d2f-5"></a><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<a name="rest_code_1f83f6559f7345b6a714749ae3593d2f-6"></a><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<a name="rest_code_1f83f6559f7345b6a714749ae3593d2f-7"></a><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
</pre>
<pre class="code ipython"><a name="rest_code_05f577985d574a79a521553346664a9b-1"></a><span class="o">%</span><span class="k">matplotlib</span> inline
<a name="rest_code_05f577985d574a79a521553346664a9b-2"></a><span class="n">seaborn</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">"whitegrid"</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="the-model">
<h3>The Model</h3>
<pre class="code ipython"><a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-1"></a><span class="k">def</span> <span class="nf">get_r_squared</span><span class="p">(</span><span class="n">max_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-2"></a>    <span class="n">train_score</span> <span class="o">=</span> <span class="p">[]</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-3"></a>    <span class="n">test_score</span> <span class="o">=</span> <span class="p">[]</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-4"></a>    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-5"></a>    <span class="n">inputs</span><span class="p">,</span> <span class="n">values</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">samples</span><span class="p">)</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-6"></a>    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-7"></a>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-8"></a>    <span class="k">for</span> <span class="n">neighbors</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_neighbors</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-9"></a>        <span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-10"></a>        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-11"></a>        <span class="n">train_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-12"></a>        <span class="n">test_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-13"></a>        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<a name="rest_code_06b63a26fabc4a07aee84ced313e5e5b-14"></a>    <span class="k">return</span> <span class="n">train_score</span><span class="p">,</span> <span class="n">test_score</span><span class="p">,</span> <span class="n">models</span>
</pre>
<pre class="code ipython"><a name="rest_code_ccb0b3d9e0dd4b5eb04cda63f68afa3a-1"></a><span class="k">def</span> <span class="nf">plot_r_squared</span><span class="p">(</span><span class="n">neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
<a name="rest_code_ccb0b3d9e0dd4b5eb04cda63f68afa3a-2"></a>    <span class="n">train_score</span><span class="p">,</span> <span class="n">test_score</span><span class="p">,</span> <span class="n">models</span> <span class="o">=</span> <span class="n">get_r_squared</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
<a name="rest_code_ccb0b3d9e0dd4b5eb04cda63f68afa3a-3"></a>    <span class="n">neighbors</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">neighbors</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<a name="rest_code_ccb0b3d9e0dd4b5eb04cda63f68afa3a-4"></a>    <span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">train_score</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Training $r^2$"</span><span class="p">)</span>
<a name="rest_code_ccb0b3d9e0dd4b5eb04cda63f68afa3a-5"></a>    <span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">test_score</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Testing $r^2$"</span><span class="p">)</span>
<a name="rest_code_ccb0b3d9e0dd4b5eb04cda63f68afa3a-6"></a>    <span class="n">pyplot</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Neighbors"</span><span class="p">)</span>
<a name="rest_code_ccb0b3d9e0dd4b5eb04cda63f68afa3a-7"></a>    <span class="n">pyplot</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"$r^2$"</span><span class="p">)</span>
<a name="rest_code_ccb0b3d9e0dd4b5eb04cda63f68afa3a-8"></a>    <span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"KNN Synthetic Data"</span><span class="p">)</span>
<a name="rest_code_ccb0b3d9e0dd4b5eb04cda63f68afa3a-9"></a>    <span class="n">pyplot</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<a name="rest_code_ccb0b3d9e0dd4b5eb04cda63f68afa3a-10"></a>    <span class="k">return</span> <span class="n">train_score</span><span class="p">,</span> <span class="n">test_score</span><span class="p">,</span> <span class="n">models</span>
<a name="rest_code_ccb0b3d9e0dd4b5eb04cda63f68afa3a-11"></a><span class="n">plot_r_squared</span><span class="p">()</span>
</pre>
<img alt="synthetic_r2.png" src="posts/knn-regression/synthetic_r2.png"><p>I originally had it set to a maximum of 10 neighbors, which made it appear that 9 was the peak, but expanding it shows that it was 15. It had a fairly low <span class="math">\(r^2\)</span> score, even at its best. There appears to be more variance in the <tt class="docutils literal">make_regression</tt> function than I had thought. When I ran it earlier the testing score never exceeded the training score and the best <tt class="docutils literal">k</tt> was 12. The actual best score was the same, though.</p>
<pre class="code ipython"><a name="rest_code_1381c670f8f9429a9cdb28f6a63754e1-1"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Max r2: {:.2f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">test_score</span><span class="p">)))</span>
</pre>
<pre class="literal-block">
Max r2: 0.47
</pre>
<p>The default for the <tt class="docutils literal">make_regression</tt> function is to create 100 samples (which I mimicked by passing in 100 explicitly). By statistics standards this is a reasonable dataset (I believe 20 samples was the minimum for a long time) but it is very small by machine learning samples. Will it do better if it has a larger sample size?</p>
<pre class="code ipython"><a name="rest_code_cc25d62a77ed413280b333235e71179e-1"></a><span class="n">plot_r_squared</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre>
<img alt="synthetic_regression_1000.png" src="posts/knn-regression/synthetic_regression_1000.png"><p>It didn't, but maybe because I didn't increase the number of neighbors.</p>
<pre class="code ipython"><a name="rest_code_ead67efba83f4a0fb1408e44d2908e28-1"></a><span class="n">plot_r_squared</span><span class="p">(</span><span class="n">neighbors</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</pre>
<img alt="synthetic_regression_100_1000.png" src="posts/knn-regression/synthetic_regression_100_1000.png"><p>No, that didn't help, and after re-looking at the plot above I realized that it was getting worse at the end, so I shouldn't have expected that to help. So why does it do worse with more data?</p>
<pre class="code ipython"><a name="rest_code_89078c6610ee4a479c5a036d65e6bc40-1"></a><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">models</span> <span class="o">=</span> <span class="n">plot_r_squared</span><span class="p">(</span><span class="n">samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span> <span class="n">neighbors</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre>
<img alt="synthetic_10000.png" src="posts/knn-regression/synthetic_10000.png"><p>Having even more data seems to have improved the amount the testing score goes down with the number of neighbors. Maybe there's an ideal neighbors to data points ratio that I'm missing, and too many neighbors means you need more data.</p>
<pre class="code ipython"><a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-1"></a><span class="nd">@jit</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-2"></a><span class="k">def</span> <span class="nf">find_first</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">match</span><span class="p">):</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-3"></a>    <span class="sd">"""find the index of the first match</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-4"></a>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-5"></a><span class="sd">    Expects a 1-dimensional array or list</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-6"></a>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-7"></a><span class="sd">    Args:</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-8"></a><span class="sd">     array (numpy.array): thing to search</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-9"></a><span class="sd">     match: thing to match</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-10"></a>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-11"></a><span class="sd">    Returns:</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-12"></a><span class="sd">     int: index of the first match found (or None)</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-13"></a><span class="sd">    """</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-14"></a>    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">array</span><span class="p">)):</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-15"></a>        <span class="k">if</span> <span class="n">array</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">==</span> <span class="n">match</span><span class="p">:</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-16"></a>            <span class="k">return</span> <span class="n">index</span>
<a name="rest_code_40cafbe932ef4d5690cab58cdaa7fea5-17"></a>    <span class="k">return</span>
</pre>
<pre class="code ipython"><a name="rest_code_db4c4b79c205475a843b8526ff8385fa-1"></a><span class="n">best</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<a name="rest_code_db4c4b79c205475a843b8526ff8385fa-2"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Best Test r2: {:.2f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best</span><span class="p">))</span>
<a name="rest_code_db4c4b79c205475a843b8526ff8385fa-3"></a><span class="n">test</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<a name="rest_code_db4c4b79c205475a843b8526ff8385fa-4"></a><span class="n">index</span> <span class="o">=</span> <span class="n">find_first</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">best</span><span class="p">)</span>
<a name="rest_code_db4c4b79c205475a843b8526ff8385fa-5"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Best Neighbors: {0}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
</pre>
<pre class="literal-block">
Best Test r2: 0.39
Best Neighbors: 18
</pre>
</div>
</div>
<div class="section" id="boston">
<h2>Boston</h2>
<p>This dataset was created to see if there was a correlation between polution and the price of houses in the Boston area.</p>
<div class="section" id="id1">
<h3>Imports</h3>
<pre class="code ipython"><a name="rest_code_3d794ccdb2874484b28dfb844c4396d5-1"></a><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pyplot</span>
<a name="rest_code_3d794ccdb2874484b28dfb844c4396d5-2"></a><span class="kn">import</span> <span class="nn">seaborn</span>
<a name="rest_code_3d794ccdb2874484b28dfb844c4396d5-3"></a><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<a name="rest_code_3d794ccdb2874484b28dfb844c4396d5-4"></a><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<a name="rest_code_3d794ccdb2874484b28dfb844c4396d5-5"></a><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
</pre>
<pre class="code ipython"><a name="rest_code_a27cdb06766045dd830cb88b3a1a9856-1"></a><span class="o">%</span><span class="k">matplotlib</span> inline
<a name="rest_code_a27cdb06766045dd830cb88b3a1a9856-2"></a><span class="n">seaborn</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">"whitegrid"</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="the-data">
<h3>The Data</h3>
<pre class="code ipython"><a name="rest_code_adab4a1d40f04563ad26ec7bafecd688-1"></a><span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<a name="rest_code_adab4a1d40f04563ad26ec7bafecd688-2"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Boston data-shape: {0}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre>
<pre class="literal-block">
Boston data-shape: (506, 13)
</pre>
<div class="section" id="boston-house-prices-dataset">
<h4>Boston House Prices dataset</h4>
<div class="section" id="notes">
<h5>Notes</h5>
<p>Data Set Characteristics:</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name">
<col class="field-body">
<tbody valign="top">
<tr class="field"><th class="field-name" colspan="2">Number of Instances:</th></tr>
<tr class="field">
<td> </td>
<td class="field-body">506</td>
</tr>
<tr class="field"><th class="field-name" colspan="2">Number of Attributes:</th></tr>
<tr class="field">
<td> </td>
<td class="field-body">13 numeric/categorical predictive</td>
</tr>
<tr class="field">
<th class="field-name">Median Value:</th>
<td class="field-body">(attribute 14) is usually the target</td>
</tr>
<tr class="field"><th class="field-name" colspan="2">Attribute Information (in order):</th></tr>
<tr class="field">
<td> </td>
<td class="field-body"></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li>CRIM     per capita crime rate by town</li>
<li>ZN       proportion of residential land zoned for lots over 25,000 sq.ft.</li>
<li>INDUS    proportion of non-retail business acres per town</li>
<li>CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)</li>
<li>NOX      nitric oxides concentration (parts per 10 million)</li>
<li>RM       average number of rooms per dwelling</li>
<li>AGE      proportion of owner-occupied units built prior to 1940</li>
<li>DIS      weighted distances to five Boston employment centres</li>
<li>RAD      index of accessibility to radial highways</li>
<li>TAX      full-value property-tax rate per $10,000</li>
<li>PTRATIO  pupil-teacher ratio by town</li>
<li>B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town</li>
<li>LSTAT    % lower status of the population</li>
<li>MEDV     Median value of owner-occupied homes in $1000's</li>
</ul>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name">
<col class="field-body">
<tbody valign="top">
<tr class="field"><th class="field-name" colspan="2">Missing Attribute Values:</th></tr>
<tr class="field">
<td> </td>
<td class="field-body">None</td>
</tr>
<tr class="field">
<th class="field-name">Creator:</th>
<td class="field-body">Harrison, D. and Rubinfeld, D.L.</td>
</tr>
</tbody>
</table>
<p>This is a copy of UCI ML housing dataset.
<a class="reference external" href="http://archive.ics.uci.edu/ml/datasets/Housing">http://archive.ics.uci.edu/ml/datasets/Housing</a></p>
<p>This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.</p>
<p>The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic
prices and the demand for clean air', J. Environ. Economics &amp; Management,
vol.5, 81-102, 1978.   Used in Belsley, Kuh &amp; Welsch, 'Regression diagnostics
...', Wiley, 1980.   N.B. Various transformations are used in the table on
pages 244-261 of the latter.</p>
<p>The Boston house-price data has been used in many machine learning papers that address regression
problems.</p>
</div>
<div class="section" id="references">
<h5>References</h5>
<ul class="simple">
<li>Belsley, Kuh &amp; Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.</li>
<li>Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.</li>
<li>many more! (see <a class="reference external" href="http://archive.ics.uci.edu/ml/datasets/Housing">http://archive.ics.uci.edu/ml/datasets/Housing</a>)</li>
</ul>
<pre class="code ipython"><a name="rest_code_8cac89ada4e64b3e8af7e953c4fff064-1"></a><span class="k">print</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre>
<pre class="literal-block">
dict_keys(['target', 'feature_names', 'data', 'DESCR'])
</pre>
<p>This time there's no target-names because it is a regression problem instead of a classification problem.</p>
<pre class="code ipython"><a name="rest_code_81b30a86c3664136bd98dbe20a4abc6a-1"></a><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</pre>
</div>
</div>
</div>
<div class="section" id="model-performance">
<h3>Model Performance</h3>
<pre class="code ipython"><a name="rest_code_7a283897149f4e2b9cb7f5a6a666d1d2-1"></a><span class="k">def</span> <span class="nf">get_r_squared</span><span class="p">(</span><span class="n">max_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<a name="rest_code_7a283897149f4e2b9cb7f5a6a666d1d2-2"></a>    <span class="n">train_score</span> <span class="o">=</span> <span class="p">[]</span>
<a name="rest_code_7a283897149f4e2b9cb7f5a6a666d1d2-3"></a>    <span class="n">test_score</span> <span class="o">=</span> <span class="p">[]</span>
<a name="rest_code_7a283897149f4e2b9cb7f5a6a666d1d2-4"></a>    <span class="n">models</span> <span class="o">=</span> <span class="p">[]</span>
<a name="rest_code_7a283897149f4e2b9cb7f5a6a666d1d2-5"></a>    <span class="k">for</span> <span class="n">neighbors</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_neighbors</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
<a name="rest_code_7a283897149f4e2b9cb7f5a6a666d1d2-6"></a>        <span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">neighbors</span><span class="p">)</span>
<a name="rest_code_7a283897149f4e2b9cb7f5a6a666d1d2-7"></a>        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<a name="rest_code_7a283897149f4e2b9cb7f5a6a666d1d2-8"></a>        <span class="n">train_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<a name="rest_code_7a283897149f4e2b9cb7f5a6a666d1d2-9"></a>        <span class="n">test_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<a name="rest_code_7a283897149f4e2b9cb7f5a6a666d1d2-10"></a>        <span class="n">models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<a name="rest_code_7a283897149f4e2b9cb7f5a6a666d1d2-11"></a>    <span class="k">return</span> <span class="n">train_score</span><span class="p">,</span> <span class="n">test_score</span><span class="p">,</span> <span class="n">models</span>
</pre>
<pre class="code ipython"><a name="rest_code_07890de031114d559d49e9b490007c81-1"></a><span class="n">train_score</span><span class="p">,</span> <span class="n">test_score</span><span class="p">,</span> <span class="n">models</span> <span class="o">=</span> <span class="n">get_r_squared</span><span class="p">()</span>
<a name="rest_code_07890de031114d559d49e9b490007c81-2"></a><span class="n">neighbors</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<a name="rest_code_07890de031114d559d49e9b490007c81-3"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">train_score</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Training $r^2$"</span><span class="p">)</span>
<a name="rest_code_07890de031114d559d49e9b490007c81-4"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">test_score</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Testing $r^2$"</span><span class="p">)</span>
<a name="rest_code_07890de031114d559d49e9b490007c81-5"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Neighbors"</span><span class="p">)</span>
<a name="rest_code_07890de031114d559d49e9b490007c81-6"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"$r^2$"</span><span class="p">)</span>
<a name="rest_code_07890de031114d559d49e9b490007c81-7"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"KNN Boston Housing Prices"</span><span class="p">)</span>
<a name="rest_code_07890de031114d559d49e9b490007c81-8"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre>
<img alt="boston_r2.png" src="posts/knn-regression/boston_r2.png"><p>The testing score seems to peak at 2 neighbors and then go down from there.</p>
<pre class="code ipython"><a name="rest_code_c85586be07cf4440940907d38219aa13-1"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Training r2 for 2 neigbors: {:.2f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">train_score</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<a name="rest_code_c85586be07cf4440940907d38219aa13-2"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Testing r2 for 2 neighbors: {:.2f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_score</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<a name="rest_code_c85586be07cf4440940907d38219aa13-3"></a><span class="k">assert</span> <span class="nb">max</span><span class="p">(</span><span class="n">test_score</span><span class="p">)</span> <span class="o">==</span> <span class="n">test_score</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre>
<pre class="literal-block">
Training r2 for 2 neigbors: 0.84
Testing r2 for 2 neighbors: 0.63
</pre>
<p>In this case the K-Nearest Neighbors didn't seem to do as well with regression as it did with classification.</p>
</div>
</div>
</div>
    </div>
    </article><article class="h-entry post-text"><header><h1 class="p-name entry-title"><a href="posts/knn-classification/" class="u-url">KNN Classification</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                hades
            </span></p>
            <p class="dateline"><a href="posts/knn-classification/" rel="bookmark"><time class="published dt-published" datetime="2017-07-09T19:00:00-07:00" title="2017-07-09 19:00">2017-07-09 19:00</time></a></p>
        </div>
    </header><div class="e-content entry-content">
    <div>
<div class="section" id="introduction">
<h2>1 Introduction</h2>
<p>This looks at the performance of the K-Nearest Neighbors for classification. K-Nearest Neighbors works by finding the <tt class="docutils literal">k</tt> (count) of neighbors that are closest to the data-point and classifying the point using the majority vote of those points. I'm going to use the default distance measurement of Euclidean distance. Fitting in this case means memorizing all the data so you can use it for predictions and then doing the calculations when you need to make a prediction. This makes it memory-intensive and slower when it's used to make predictions, so it's useful as a baseline, but not in production.</p>
</div>
<div class="section" id="synthetic">
<h2>2 Synthetic</h2>
<p>I'll start with a synthetic data set created by sklean. I'll make it the same shape as the Breast Cancer case that I'll look at later.</p>
<div class="section" id="imports">
<h3>2.1 Imports</h3>
<pre class="code python"><a name="rest_code_c9436bcdbe0e43278fa15dda7d4e0327-1"></a><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<a name="rest_code_c9436bcdbe0e43278fa15dda7d4e0327-2"></a><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<a name="rest_code_c9436bcdbe0e43278fa15dda7d4e0327-3"></a><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<a name="rest_code_c9436bcdbe0e43278fa15dda7d4e0327-4"></a><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pyplot</span>
<a name="rest_code_c9436bcdbe0e43278fa15dda7d4e0327-5"></a><span class="kn">import</span> <span class="nn">seaborn</span>
</pre>
<pre class="code python"><a name="rest_code_23fdcae0274440e48beb87d6bd23e5f6-1"></a><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<a name="rest_code_23fdcae0274440e48beb87d6bd23e5f6-2"></a><span class="n">seaborn</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">"whitegrid"</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="the-data">
<h3>2.2 The Data</h3>
<pre class="code python"><a name="rest_code_a04288e3dfe94474891396566bcd0bc3-1"></a><span class="n">total</span> <span class="o">=</span> <span class="mi">569</span>
<a name="rest_code_a04288e3dfe94474891396566bcd0bc3-2"></a><span class="n">positive_fraction</span> <span class="o">=</span> <span class="mi">212</span><span class="o">/</span><span class="n">total</span>
<a name="rest_code_a04288e3dfe94474891396566bcd0bc3-3"></a><span class="n">negative_fraction</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">positive_fraction</span>
<a name="rest_code_a04288e3dfe94474891396566bcd0bc3-4"></a><span class="n">inputs</span><span class="p">,</span> <span class="n">classifications</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">total</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
<a name="rest_code_a04288e3dfe94474891396566bcd0bc3-5"></a>                                              <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">positive_fraction</span><span class="p">,</span>
<a name="rest_code_a04288e3dfe94474891396566bcd0bc3-6"></a>                                                       <span class="n">negative_fraction</span><span class="p">])</span>
<a name="rest_code_a04288e3dfe94474891396566bcd0bc3-7"></a><span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<a name="rest_code_a04288e3dfe94474891396566bcd0bc3-8"></a><span class="k">print</span><span class="p">(</span><span class="n">classifications</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre>
<pre class="literal-block">
(569, 30)
(569,)
</pre>
<pre class="code python"><a name="rest_code_a126483cdfa04664bd4e56fd261d8be3-1"></a><span class="n">positive</span> <span class="o">=</span> <span class="n">classifications</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<a name="rest_code_a126483cdfa04664bd4e56fd261d8be3-2"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Positives: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">positive</span><span class="p">))</span>
<a name="rest_code_a126483cdfa04664bd4e56fd261d8be3-3"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Negatives: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">classifications</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="n">positive</span><span class="p">))</span>
</pre>
<pre class="literal-block">
Positives: 355
Negatives: 214
</pre>
<pre class="code python"><a name="rest_code_cd8e8778e7d44223a8bc7bfaa90cbb3b-1"></a><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">classifications</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="the-model">
<h3>2.3 The model</h3>
<pre class="code python"><a name="rest_code_b39621b97e8647969196700ff40d842a-1"></a><span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
</pre>
<pre class="code python"><a name="rest_code_f7c0dc77d0c240918575eb7f29a24798-1"></a><span class="k">def</span> <span class="nf">get_accuracies</span><span class="p">(</span><span class="n">max_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<a name="rest_code_f7c0dc77d0c240918575eb7f29a24798-2"></a>    <span class="n">train_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<a name="rest_code_f7c0dc77d0c240918575eb7f29a24798-3"></a>    <span class="n">test_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<a name="rest_code_f7c0dc77d0c240918575eb7f29a24798-4"></a>    <span class="k">for</span> <span class="n">neighbors</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span>  <span class="n">max_neighbors</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
<a name="rest_code_f7c0dc77d0c240918575eb7f29a24798-5"></a>        <span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">neighbors</span><span class="p">)</span>
<a name="rest_code_f7c0dc77d0c240918575eb7f29a24798-6"></a>        <span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<a name="rest_code_f7c0dc77d0c240918575eb7f29a24798-7"></a>        <span class="n">train_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<a name="rest_code_f7c0dc77d0c240918575eb7f29a24798-8"></a>        <span class="n">test_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<a name="rest_code_f7c0dc77d0c240918575eb7f29a24798-9"></a>    <span class="k">return</span> <span class="n">train_accuracies</span><span class="p">,</span> <span class="n">test_accuracies</span>
</pre>
<pre class="code python"><a name="rest_code_6cff109fb6384cfeb3cb6f8b1ef4e9f0-1"></a><span class="n">training_accuracies</span><span class="p">,</span> <span class="n">testing_accuracies</span> <span class="o">=</span> <span class="n">get_accuracies</span><span class="p">()</span>
</pre>
<pre class="code python"><a name="rest_code_b516142a28614e45aa98822c775ffce9-1"></a><span class="n">neighbors</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<a name="rest_code_b516142a28614e45aa98822c775ffce9-2"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">training_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Training Accuracy"</span><span class="p">)</span>
<a name="rest_code_b516142a28614e45aa98822c775ffce9-3"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">testing_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Testing Accuracy"</span><span class="p">)</span>
<a name="rest_code_b516142a28614e45aa98822c775ffce9-4"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"Accuracy"</span><span class="p">)</span>
<a name="rest_code_b516142a28614e45aa98822c775ffce9-5"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Neighbors"</span><span class="p">)</span>
<a name="rest_code_b516142a28614e45aa98822c775ffce9-6"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"KNN Cancer Accuracy"</span><span class="p">)</span>
<a name="rest_code_b516142a28614e45aa98822c775ffce9-7"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre>
<img alt="knn_synthetic_accuracy.png" src="posts/knn-classification/knn_synthetic_accuracy.png"><p>At <em>k=1</em>, the training set does perfectly while the test set does okay, but not as well as it does at <em>k=9</em>, what appears to be the best value.</p>
</div>
</div>
<div class="section" id="breast-cancer">
<h2>3 Breast Cancer</h2>
<div class="section" id="id1">
<h3>3.1 Imports</h3>
<pre class="code python"><a name="rest_code_ec9e4d4c65d247fab84f764df50610c6-1"></a><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pyplot</span>
<a name="rest_code_ec9e4d4c65d247fab84f764df50610c6-2"></a><span class="kn">import</span> <span class="nn">seaborn</span>
<a name="rest_code_ec9e4d4c65d247fab84f764df50610c6-3"></a><span class="kn">import</span> <span class="nn">pandas</span>
<a name="rest_code_ec9e4d4c65d247fab84f764df50610c6-4"></a><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<a name="rest_code_ec9e4d4c65d247fab84f764df50610c6-5"></a><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<a name="rest_code_ec9e4d4c65d247fab84f764df50610c6-6"></a><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
</pre>
<pre class="code python"><a name="rest_code_00c0443f17614b7ebf85528156779cf9-1"></a><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<a name="rest_code_00c0443f17614b7ebf85528156779cf9-2"></a><span class="n">seaborn</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">"whitegrid"</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="the-dataset">
<h3>3.2 The Dataset</h3>
<pre class="code python"><a name="rest_code_a067c40db6d945f7825772ca702d6c5a-1"></a><span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<a name="rest_code_a067c40db6d945f7825772ca702d6c5a-2"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Keys in the cancer bunch: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">","</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>
<a name="rest_code_a067c40db6d945f7825772ca702d6c5a-3"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Training Data Shape: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<a name="rest_code_a067c40db6d945f7825772ca702d6c5a-4"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Target Names: {}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">','</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span><span class="p">)))</span>
</pre>
<pre class="literal-block">
Keys in the cancer bunch: feature_names,target_names,target,data,DESCR
Training Data Shape: (569, 30)
Target Names: malignant,benign
</pre>
<p>This is from the description.</p>
<dl class="docutils">
<dt>Data Set Characteristics:</dt>
<dd><table class="first last docutils field-list" frame="void" rules="none">
<col class="field-name">
<col class="field-body">
<tbody valign="top">
<tr class="field"><th class="field-name" colspan="2">Number of Instances:</th></tr>
<tr class="field">
<td> </td>
<td class="field-body">569</td>
</tr>
</tbody>
</table></dd>
</dl>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name">
<col class="field-body">
<tbody valign="top">
<tr class="field"><th class="field-name" colspan="2">Number of Attributes:</th></tr>
<tr class="field">
<td> </td>
<td class="field-body">30 numeric, predictive attributes and the class</td>
</tr>
<tr class="field"><th class="field-name" colspan="2">Attribute Information:</th></tr>
<tr class="field">
<td> </td>
<td class="field-body"></td>
</tr>
</tbody>
</table>
<ul class="simple">
<li>radius (mean of distances from center to points on the perimeter)</li>
<li>texture (standard deviation of gray-scale values)</li>
<li>perimeter</li>
<li>area</li>
<li>smoothness (local variation in radius lengths)</li>
<li>compactness (perimeter^2 / area - 1.0)</li>
<li>concavity (severity of concave portions of the contour)</li>
<li>concave points (number of concave portions of the contour)</li>
<li>symmetry</li>
<li>fractal dimension ("coastline approximation" - 1)</li>
</ul>
<p>The mean, standard error, and "worst" or largest (mean of the three
largest values) of these features were computed for each image,
resulting in 30 features.  For instance, field 3 is Mean Radius, field
13 is Radius SE, field 23 is Worst Radius.</p>
<ul class="simple">
<li>class:<ul>
<li>WDBC-Malignant</li>
<li>WDBC-Benign</li>
</ul>
</li>
</ul>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name">
<col class="field-body">
<tbody valign="top">
<tr class="field"><th class="field-name" colspan="2">Missing Attribute Values:</th></tr>
<tr class="field">
<td> </td>
<td class="field-body">None</td>
</tr>
<tr class="field"><th class="field-name" colspan="2">Class Distribution:</th></tr>
<tr class="field">
<td> </td>
<td class="field-body">212 - Malignant, 357 - Benign</td>
</tr>
<tr class="field">
<th class="field-name">Creator:</th>
<td class="field-body">Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian</td>
</tr>
<tr class="field">
<th class="field-name">Donor:</th>
<td class="field-body">Nick Street</td>
</tr>
<tr class="field">
<th class="field-name">Date:</th>
<td class="field-body">November, 1995</td>
</tr>
</tbody>
</table>
<p>This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.
<a class="reference external" href="https://goo.gl/U2Uwz2">https://goo.gl/U2Uwz2</a></p>
<p>Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image.</p>
<p>Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, "Decision Tree Construction Via Linear Programming." Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.</p>
<p>The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in:
[K. P. Bennett and O. L. Mangasarian: "Robust Linear Programming Discrimination of Two Linearly Inseparable Sets",
Optimization Methods and Software 1, 1992, 23-34].</p>
<p>This database is also available through the UW CS ftp server:</p>
<p>ftp ftp.cs.wisc.edu
cd math-prog/cpo-dataset/machine-learn/WDBC/</p>
</div>
<div class="section" id="references">
<h3>References</h3>
<ul class="simple">
<li>W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction
for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on
Electronic Imaging: Science and Technology, volume 1905, pages 861-870,
San Jose, CA, 1993.</li>
<li>O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and
prognosis via linear programming. Operations Research, 43(4), pages 570-577,
July-August 1995.</li>
<li>W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques
to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)
163-171.</li>
</ul>
</div>
<div class="section" id="loading-the-data">
<h3>Loading the Data</h3>
<pre class="code python"><a name="rest_code_f310007022f9418f81d0ba1c71a04795-1"></a><span class="n">target</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">))</span>
<a name="rest_code_f310007022f9418f81d0ba1c71a04795-2"></a><span class="n">target_map</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span><span class="p">)),</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span><span class="p">))</span>
<a name="rest_code_f310007022f9418f81d0ba1c71a04795-3"></a><span class="n">target</span><span class="p">[</span><span class="s1">'name'</span><span class="p">]</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">entry</span><span class="p">:</span> <span class="n">target_map</span><span class="p">[</span><span class="n">entry</span><span class="p">])</span>
<a name="rest_code_f310007022f9418f81d0ba1c71a04795-4"></a><span class="k">print</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre>
<pre class="literal-block">
benign       357
malignant    212
Name: name, dtype: int64
</pre>
</div>
<div class="section" id="splitting-the-data">
<h3>3.3 Splitting the Data</h3>
<pre class="code python"><a name="rest_code_3fd49ba51d9c47fe8ed87385895d180f-1"></a><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<a name="rest_code_3fd49ba51d9c47fe8ed87385895d180f-2"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Trainining percent: {0:.2f} %"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)))</span>
<a name="rest_code_3fd49ba51d9c47fe8ed87385895d180f-3"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Testing percent: {0:.2f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)))</span>
</pre>
<pre class="literal-block">
Trainining percent: 74.87 %
Testing percent: 25.13
</pre>
</div>
<div class="section" id="model-performance">
<h3>3.4 Model Performance</h3>
<pre class="code python"><a name="rest_code_259d7b26a30d4bc189697079748675c5-1"></a><span class="k">def</span> <span class="nf">get_accuracies</span><span class="p">(</span><span class="n">max_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<a name="rest_code_259d7b26a30d4bc189697079748675c5-2"></a>    <span class="n">train_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<a name="rest_code_259d7b26a30d4bc189697079748675c5-3"></a>    <span class="n">test_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<a name="rest_code_259d7b26a30d4bc189697079748675c5-4"></a>    <span class="k">for</span> <span class="n">neighbors</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span>  <span class="n">max_neighbors</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
<a name="rest_code_259d7b26a30d4bc189697079748675c5-5"></a>        <span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">neighbors</span><span class="p">)</span>
<a name="rest_code_259d7b26a30d4bc189697079748675c5-6"></a>        <span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<a name="rest_code_259d7b26a30d4bc189697079748675c5-7"></a>        <span class="n">train_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
<a name="rest_code_259d7b26a30d4bc189697079748675c5-8"></a>        <span class="n">test_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<a name="rest_code_259d7b26a30d4bc189697079748675c5-9"></a>    <span class="k">return</span> <span class="n">train_accuracies</span><span class="p">,</span> <span class="n">test_accuracies</span>
</pre>
<pre class="code python"><a name="rest_code_2f2cd28891d14e37bcc68ad646228ed5-1"></a><span class="n">training_accuracies</span><span class="p">,</span> <span class="n">testing_accuracies</span> <span class="o">=</span> <span class="n">get_accuracies</span><span class="p">()</span>
</pre>
<pre class="code python"><a name="rest_code_3a115a2368f54392bf073512778effe1-1"></a><span class="n">neighbors</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<a name="rest_code_3a115a2368f54392bf073512778effe1-2"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">training_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Training Accuracy"</span><span class="p">)</span>
<a name="rest_code_3a115a2368f54392bf073512778effe1-3"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">testing_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Testing Accuracy"</span><span class="p">)</span>
<a name="rest_code_3a115a2368f54392bf073512778effe1-4"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">"Accuracy"</span><span class="p">)</span>
<a name="rest_code_3a115a2368f54392bf073512778effe1-5"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">"Neighbors"</span><span class="p">)</span>
<a name="rest_code_3a115a2368f54392bf073512778effe1-6"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"KNN Cancer Accuracy"</span><span class="p">)</span>
<a name="rest_code_3a115a2368f54392bf073512778effe1-7"></a><span class="n">pyplot</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre>
<img alt="knn_cancer_accuracy.png" src="posts/knn-classification/knn_cancer_accuracy.png"><p>It looks like five neighbors would be what you'd want.</p>
<pre class="code python"><a name="rest_code_c7275df4c38242b6a7410cea35ed7a7d-1"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Minimum test accuracy (n=1): {:.2f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">testing_accuracies</span><span class="p">)))</span>
<a name="rest_code_c7275df4c38242b6a7410cea35ed7a7d-2"></a><span class="k">print</span><span class="p">(</span><span class="s2">"Maximum test accuracy (n=5): {:.2f}"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">testing_accuracies</span><span class="p">)))</span>
<a name="rest_code_c7275df4c38242b6a7410cea35ed7a7d-3"></a><span class="k">assert</span> <span class="nb">max</span><span class="p">(</span><span class="n">testing_accuracies</span> <span class="o">==</span> <span class="n">testing_accuracies</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span>
</pre>
<pre class="literal-block">
Minimum test accuracy (n=1): 0.90
Maximum test accuracy (n=5): 0.92
</pre>
<p>The original paper that used this data-set got a cross-validation error-rate of 3%, but it sounds like they didn't split the data into training and testing sets (I'll have to re-read the paper to be sure).</p>
</div>
</div>
</div>
    </div>
    </article>
</div>







        </div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2017         <a href="mailto:necromuralist@gmail.com">necromuralist</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>
