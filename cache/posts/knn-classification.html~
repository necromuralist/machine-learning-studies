
<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">Introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
This looks at the performance of the K-Nearest Neighbors for classification. K-Nearest Neighbors works by finding the <code>k</code> (count) of neighbors that are closest to the data-point and classifying the point using the majority vote of those points. I'm going to use the default distance measurement of Euclidean distance. Fitting in this case means memorizing all the data so you can use it for predictions and then doing the calculations when you need to make a prediction. This makes it memory-intensive and slower when it's used to make predictions, so it's useful as a baseline, but not in production.
</p>
</div>
</div>
<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">Synthetic</h2>
<div class="outline-text-2" id="text-2">
<p>
I'll start with a synthetic data set created by sklean. I'll make it the same shape as the Breast Cancer case that I'll look at later.
</p>
</div>
<div id="outline-container-sec-2-1" class="outline-3">
<h3 id="sec-2-1">Imports</h3>
<div class="outline-text-3" id="text-2-1">
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
</pre></div>

<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div id="outline-container-sec-2-2" class="outline-3">
<h3 id="sec-2-2">The Data</h3>
<div class="outline-text-3" id="text-2-2">
<div class="highlight"><pre><span></span><span class="n">total</span> <span class="o">=</span> <span class="mi">569</span>
<span class="n">positive_fraction</span> <span class="o">=</span> <span class="mi">212</span><span class="o">/</span><span class="n">total</span>
<span class="n">negative_fraction</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">positive_fraction</span>
<span class="n">inputs</span><span class="p">,</span> <span class="n">classifications</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">total</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
					      <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">positive_fraction</span><span class="p">,</span>
						       <span class="n">negative_fraction</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classifications</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

<div class="highlight"><pre><span></span><span class="n">positive</span> <span class="o">=</span> <span class="n">classifications</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Positives: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">positive</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Negatives: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">classifications</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="n">positive</span><span class="p">))</span>
</pre></div>

<div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">classifications</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div id="outline-container-sec-2-3" class="outline-3">
<h3 id="sec-2-3">The model</h3>
<div class="outline-text-3" id="text-2-3">
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span>
</pre></div>

<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_accuracies</span><span class="p">(</span><span class="n">max_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">train_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">neighbors</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span>  <span class="n">max_neighbors</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
	<span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">neighbors</span><span class="p">)</span>
	<span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
	<span class="n">train_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
	<span class="n">test_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">train_accuracies</span><span class="p">,</span> <span class="n">test_accuracies</span>
</pre></div>

<div class="highlight"><pre><span></span><span class="n">training_accuracies</span><span class="p">,</span> <span class="n">testing_accuracies</span> <span class="o">=</span> <span class="n">get_accuracies</span><span class="p">()</span>
</pre></div>

<div class="highlight"><pre><span></span><span class="n">neighbors</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">training_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training Accuracy&quot;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">testing_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Testing Accuracy&quot;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Neighbors&quot;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;KNN Cancer Accuracy&quot;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>

<p>
<img src="file:///tmp/knn_synthetic_accuracy.png" alt="knn_synthetic_accuracy.png" />
At <i>k=1</i>, the training set does perfectly while the test set does okay, but not as well as it does at <i>k=9</i>, what appears to be the best value.
</p>
</div>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">Breast Cancer</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-sec-3-1" class="outline-3">
<h3 id="sec-3-1">Imports</h3>
<div class="outline-text-3" id="text-3-1">
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">pyplot</span>
<span class="kn">import</span> <span class="nn">seaborn</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
</pre></div>

<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">seaborn</span><span class="o">.</span><span class="n">set_style</span><span class="p">(</span><span class="s2">&quot;whitegrid&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-3-2" class="outline-3">
<h3 id="sec-3-2">The Dataset</h3>
<div class="outline-text-3" id="text-3-2">
<div class="highlight"><pre><span></span><span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Keys in the cancer bunch: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Training Data Shape: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Target Names: {}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span><span class="p">)))</span>
</pre></div>

<p>
This is from the description.
</p>

<blockquote>
<p>
Data Set Characteristics:
</p>
<p>
:Number of Instances: 569
</p>

<p>
:Number of Attributes: 30 numeric, predictive attributes and the class
</p>

<p>
:Attribute Information:
</p>
<ul class="org-ul">
<li>radius (mean of distances from center to points on the perimeter)
</li>
<li>texture (standard deviation of gray-scale values)
</li>
<li>perimeter
</li>
<li>area
</li>
<li>smoothness (local variation in radius lengths)
</li>
<li>compactness (perimeter<sup>2</sup> / area - 1.0)
</li>
<li>concavity (severity of concave portions of the contour)
</li>
<li>concave points (number of concave portions of the contour)
</li>
<li>symmetry 
</li>
<li>fractal dimension ("coastline approximation" - 1)
</li>
</ul>

<p>
The mean, standard error, and "worst" or largest (mean of the three
largest values) of these features were computed for each image,
resulting in 30 features.  For instance, field 3 is Mean Radius, field
13 is Radius SE, field 23 is Worst Radius.
</p>

<ul class="org-ul">
<li>class:
<ul class="org-ul">
<li>WDBC-Malignant
</li>
<li>WDBC-Benign
</li>
</ul>
</li>
</ul>
<p>
:Missing Attribute Values: None
</p>

<p>
:Class Distribution: 212 - Malignant, 357 - Benign
</p>

<p>
:Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian
</p>

<p>
:Donor: Nick Street
</p>

<p>
:Date: November, 1995
</p>

<p>
This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.
<a href="https://goo.gl/U2Uwz2">https://goo.gl/U2Uwz2</a>
</p>

<p>
Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image.
</p>

<p>
Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, "Decision Tree Construction Via Linear Programming." Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.
</p>

<p>
The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in:
[K. P. Bennett and O. L. Mangasarian: "Robust Linear Programming Discrimination of Two Linearly Inseparable Sets",
Optimization Methods and Software 1, 1992, 23-34].
</p>

<p>
This database is also available through the UW CS ftp server:
</p>

<p>
ftp ftp.cs.wisc.edu
cd math-prog/cpo-dataset/machine-learn/WDBC/
</p>

<p>
References
</p>
<hr  />
<ul class="org-ul">
<li>W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction 
for breast tumor diagnosis. IS&amp;T/SPIE 1993 International Symposium on 
Electronic Imaging: Science and Technology, volume 1905, pages 861-870,
San Jose, CA, 1993.
</li>
<li>O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and 
prognosis via linear programming. Operations Research, 43(4), pages 570-577, 
July-August 1995.
</li>
<li>W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques
to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 
163-171.
</li>
</ul>
</blockquote>

<div class="highlight"><pre><span></span><span class="n">target</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">))</span>
<span class="n">target_map</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span><span class="p">)),</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span><span class="p">))</span>
<span class="n">target</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">entry</span><span class="p">:</span> <span class="n">target_map</span><span class="p">[</span><span class="n">entry</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-3-3" class="outline-3">
<h3 id="sec-3-3">Splitting the Data</h3>
<div class="outline-text-3" id="text-3-3">
<div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Trainining percent: {0:.2f} %&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Testing percent: {0:.2f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">)))</span>
</pre></div>
</div>
</div>

<div id="outline-container-sec-3-4" class="outline-3">
<h3 id="sec-3-4">Model Performance</h3>
<div class="outline-text-3" id="text-3-4">
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_accuracies</span><span class="p">(</span><span class="n">max_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
    <span class="n">train_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_accuracies</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">neighbors</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span>  <span class="n">max_neighbors</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
	<span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">neighbors</span><span class="p">)</span>
	<span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
	<span class="n">train_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
	<span class="n">test_accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">classifier</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">train_accuracies</span><span class="p">,</span> <span class="n">test_accuracies</span>
</pre></div>

<div class="highlight"><pre><span></span><span class="n">training_accuracies</span><span class="p">,</span> <span class="n">testing_accuracies</span> <span class="o">=</span> <span class="n">get_accuracies</span><span class="p">()</span>
</pre></div>

<div class="highlight"><pre><span></span><span class="n">neighbors</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">training_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training Accuracy&quot;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors</span><span class="p">,</span> <span class="n">testing_accuracies</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Testing Accuracy&quot;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Neighbors&quot;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;KNN Cancer Accuracy&quot;</span><span class="p">)</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>

<p>
<img src="file:///tmp/knn_cancer_accuracy.png" alt="knn_cancer_accuracy.png" />
It looks like five neighbors would be what you'd want.
</p>

<div class="highlight"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">&quot;Minimum test accuracy (n=1): {:.2f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">testing_accuracies</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Maximum test accuracy (n=5): {:.2f}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">testing_accuracies</span><span class="p">)))</span>
<span class="k">assert</span> <span class="nb">max</span><span class="p">(</span><span class="n">testing_accuracies</span> <span class="o">==</span> <span class="n">testing_accuracies</span><span class="p">[</span><span class="mi">4</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
